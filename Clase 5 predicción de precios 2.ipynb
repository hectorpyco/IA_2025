{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ZTGt0wG2tOIpHumXbJuAVZcPR8v8Y1xf","timestamp":1744029449945}],"toc_visible":true,"authorship_tag":"ABX9TyM6/mqxH+f3juoxdDav59Yy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#  Entrenamiento y evaluaci√≥n usando Pandas\n"],"metadata":{"id":"kS217340ZPC9"}},{"cell_type":"code","source":["# prompt: ejemplo simple de regresion lineal usando california housing\n","\n","import pandas as pd\n","from sklearn.datasets import fetch_california_housing\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# Load the California Housing dataset\n","housing = fetch_california_housing()\n","df = pd.DataFrame(housing.data, columns=housing.feature_names)\n","df['precio'] = housing.target\n","print(df.shape)\n","print(df.head())\n","\n","\n","\n","# Prepare the data\n","X = df.drop('precio', axis=1)\n","y = df['precio']\n","print(f\"Forma de las caracter√≠sticas: {X.shape}\")\n","print(f\"Forma del objetivo: {y.shape}\")\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","print(f\"Forma de las caracter√≠sticas para entrenamiento: {X_train.shape}\")\n","print(f\"Forma de las caracter√≠sticas para prueba: {X_test.shape}\")\n","\n","# Create and train the linear regression model\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = model.predict(X_test)\n","\n","# Evaluate the model\n","mse = mean_squared_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","print(f'Mean Squared Error: {mse:.2f}')\n","print(f'R-squared: {r2:.2f}')\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gCZADlUZQo8o","executionInfo":{"status":"ok","timestamp":1744061085379,"user_tz":180,"elapsed":125,"user":{"displayName":"Hector Estigarribia FCyT UNCA","userId":"04796158545147043803"}},"outputId":"125125d8-0bb4-4bd4-c4d0-fa0b64c56c63"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["(20640, 9)\n","   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n","0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n","1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n","2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n","3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n","4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n","\n","   Longitude  precio  \n","0    -122.23   4.526  \n","1    -122.22   3.585  \n","2    -122.24   3.521  \n","3    -122.25   3.413  \n","4    -122.25   3.422  \n","Forma de las caracter√≠sticas: (20640, 8)\n","Forma del objetivo: (20640,)\n","Forma de las caracter√≠sticas para entrenamiento: (16512, 8)\n","Forma de las caracter√≠sticas para prueba: (4128, 8)\n","Mean Squared Error: 0.56\n","R-squared: 0.58\n"]}]},{"cell_type":"markdown","source":["# Entrenamiento y evaluaci√≥n sin usar Pandas"],"metadata":{"id":"i5vb1rmwZWsf"}},{"cell_type":"code","source":["from sklearn.datasets import fetch_california_housing\n","\n","# Cargar el dataset de California Housing\n","california_housing = fetch_california_housing()\n","\n","# Obtener las dimensiones de las caracter√≠sticas (X) y del objetivo (y)\n","print(f\"Forma de las caracter√≠sticas: {california_housing.data.shape}\")\n","print(f\"Forma del objetivo: {california_housing.target.shape}\")\n","\n","from sklearn.model_selection import train_test_split\n","\n","# Dividir en conjunto de entrenamiento y conjunto de prueba (80% entrenamiento, 20% prueba)\n","X_train, X_test, y_train, y_test = train_test_split(california_housing.data,\n","                                                    california_housing.target, test_size=0.2, random_state=42)\n","\n","print(f\"Forma de las caracter√≠sticas para entrenamiento: {X_train.shape}\")\n","print(f\"Forma de las caracter√≠sticas para prueba: {X_test.shape}\")\n","\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# Crear y entrenar el modelo de Regresi√≥n Lineal\n","modelo_lr = LinearRegression()\n","modelo_lr.fit(X_train, y_train)\n","\n","# Hacer predicciones\n","y_pred_lr = modelo_lr.predict(X_test)\n","\n","# Evaluar el modelo\n","mse_lr = mean_squared_error(y_test, y_pred_lr)\n","r2_lr = r2_score(y_test, y_pred_lr)\n","\n","print(f\"Resultado MSE de Regresi√≥n Lineal: {mse_lr:.2f}\")\n","print(f\"Resultado R¬≤ de Regresi√≥n Lineal: {r2_lr:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KnQZ2oneZeW-","executionInfo":{"status":"ok","timestamp":1744061631966,"user_tz":180,"elapsed":36,"user":{"displayName":"Hector Estigarribia FCyT UNCA","userId":"04796158545147043803"}},"outputId":"f6a0a94a-ce29-4a12-8109-42e2ee25b476"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Forma de las caracter√≠sticas: (20640, 8)\n","Forma del objetivo: (20640,)\n","Forma de las caracter√≠sticas para entrenamiento: (16512, 8)\n","Forma de las caracter√≠sticas para prueba: (4128, 8)\n","Resultado MSE de Regresi√≥n Lineal: 0.56\n","Resultado R¬≤ de Regresi√≥n Lineal: 0.58\n"]}]},{"cell_type":"markdown","source":["# Evaluando varios modelos\n"],"metadata":{"id":"Dhk1GKr6eU8T"}},{"cell_type":"code","source":["from sklearn.datasets import fetch_california_housing\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.svm import SVR\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# Cargar el dataset de California Housing\n","dataset = fetch_california_housing()\n","\n","# Dividir en conjunto de entrenamiento y conjunto de prueba (80% entrenamiento, 20% prueba)\n","X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.2, random_state=42)\n","print(f\"Forma de las caracter√≠sticas para entrenamiento: {X_train.shape}\")\n","print(f\"Forma de las caracter√≠sticas para prueba: {X_test.shape}\")\n","# Lista de modelos a evaluar\n","modelos = {\n","    \"Regresi√≥n Lineal\": LinearRegression(),\n","    \"√Årbol de Decisi√≥n\": DecisionTreeRegressor(max_depth=5, random_state=42),\n","    \"Bosque Aleatorio\": RandomForestRegressor(n_estimators=100, random_state=42),\n","    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n","    \"M√°quinas de Vectores de Soporte\": SVR(),\n","    \"K-Vecinos M√°s Cercanos\": KNeighborsRegressor()\n","}\n","\n","# Evaluar todos los modelos\n","for nombre, modelo in modelos.items():\n","    modelo.fit(X_train, y_train)\n","    y_pred = modelo.predict(X_test)\n","    mse = mean_squared_error(y_test, y_pred)\n","    r2 = r2_score(y_test, y_pred)\n","    print(f\"\\n{nombre}:\")\n","    print(f\"MSE: {mse:.2f}\")\n","    print(f\"R¬≤: {r2:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"shjc7BvbeSLw","executionInfo":{"status":"ok","timestamp":1744037694122,"user_tz":180,"elapsed":41516,"user":{"displayName":"Hector Estigarribia FCyT UNCA","userId":"04796158545147043803"}},"outputId":"d674196d-2453-492b-d560-e1a34063d229"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Forma de las caracter√≠sticas para entrenamiento: (16512, 8)\n","Forma de las caracter√≠sticas para prueba: (4128, 8)\n","\n","Regresi√≥n Lineal:\n","MSE: 0.56\n","R¬≤: 0.58\n","\n","√Årbol de Decisi√≥n:\n","MSE: 0.52\n","R¬≤: 0.60\n","\n","Bosque Aleatorio:\n","MSE: 0.26\n","R¬≤: 0.81\n","\n","Gradient Boosting:\n","MSE: 0.29\n","R¬≤: 0.78\n","\n","M√°quinas de Vectores de Soporte:\n","MSE: 1.33\n","R¬≤: -0.02\n","\n","K-Vecinos M√°s Cercanos:\n","MSE: 1.12\n","R¬≤: 0.15\n"]}]},{"cell_type":"markdown","source":["# **Interpretaci√≥n**\n","---\n","\n","## üìä **M√©tricas usadas**\n","\n","- **MSE (Error Cuadr√°tico Medio)**: mide el promedio de los errores al cuadrado. Cuanto **m√°s bajo**, mejor.\n","- **R¬≤ (Coeficiente de determinaci√≥n)**: mide qu√© tan bien el modelo explica la variabilidad de los datos. Va de **-‚àû a 1**, donde:\n","  - `1.0`: predicci√≥n perfecta.\n","  - `0.0`: el modelo no mejora respecto a predecir simplemente el promedio.\n","  - `< 0`: el modelo es peor que una l√≠nea horizontal (promedio).\n","\n","---\n","\n","## üìà **Interpretaci√≥n de los modelos**\n","\n","### 1. **Regresi√≥n Lineal**\n","- `MSE: 0.56`, `R¬≤: 0.58`\n","- ‚úîÔ∏è Bastante decente para un modelo simple.\n","- ‚ùó Suponiendo que la relaci√≥n entre las variables y el precio es lineal, lo cual puede no ser del todo cierto.\n","\n","---\n","\n","### 2. **√Årbol de Decisi√≥n**\n","- `MSE: 0.52`, `R¬≤: 0.60`\n","- ‚úîÔ∏è Mejora un poco a la regresi√≥n lineal.\n","- ‚ùó Puede estar empezando a sobreajustar si lo dejas crecer demasiado.\n","\n","---\n","\n","### 3. **Random Forest (Bosque Aleatorio)**\n","- `MSE: 0.26`, `R¬≤: 0.81`\n","- üî• **El mejor modelo por ahora**.\n","- ‚úîÔ∏è Combina muchos √°rboles d√©biles para hacer uno fuerte.\n","- ‚úîÔ∏è Generaliza bien, evita sobreajuste.\n","- ‚úÖ Muy usado en producci√≥n.\n","\n","---\n","\n","### 4. **Gradient Boosting**\n","- `MSE: 0.29`, `R¬≤: 0.78`\n","- ‚ö° Muy buen modelo tambi√©n.\n","- ‚úîÔ∏è Corrige errores de modelos anteriores en cadena.\n","- ‚úÖ Suele ser m√°s preciso pero m√°s lento que Random Forest.\n","\n","---\n","\n","### 5. **SVR (M√°quinas de Vectores de Soporte)**\n","- `MSE: 1.33`, `R¬≤: -0.02`\n","- üö´ Muy mal desempe√±o aqu√≠.\n","- ‚ùó SVR no escala bien sin normalizaci√≥n previa.\n","- ‚ùó No est√° dise√±ado para datasets grandes sin ajuste.\n","\n","---\n","\n","### 6. **K-Vecinos M√°s Cercanos**\n","- `MSE: 1.12`, `R¬≤: 0.15`\n","- üê¢ Bastante flojo.\n","- ‚ùó Muy sensible a la escala y distribuci√≥n de los datos.\n","- ‚ùó Requiere mucha memoria y no aprende patrones generales.\n","\n","---\n","\n","## üéØ Conclusi√≥n\n","\n","- **Ganador claro**: üî• **Random Forest**.\n","- **Gradient Boosting** es una gran segunda opci√≥n.\n","- **Regresi√≥n Lineal** y **√Årbol de Decisi√≥n** son buenos como base.\n","- ‚ùå **SVR** y **KNN** necesitan mucha m√°s preparaci√≥n de datos para brillar (normalizaci√≥n, ajuste de hiperpar√°metros, etc.)."],"metadata":{"id":"RhHfiNaasQB4"}},{"cell_type":"markdown","source":["# M√°s modelos y medidas de error\n"],"metadata":{"id":"v_3jcJ0IvUBM"}},{"cell_type":"code","source":["from sklearn.datasets import fetch_california_housing\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.svm import SVR\n","from sklearn.neighbors import KNeighborsRegressor\n","\n","from sklearn.metrics import (\n","    mean_absolute_error, mean_squared_error,\n","    median_absolute_error, r2_score, max_error\n",")\n","import numpy as np\n","import pandas as pd\n","\n","# Cargar dataset\n","dataset = fetch_california_housing()\n","X_train, X_test, y_train, y_test = train_test_split(\n","    dataset.data, dataset.target, test_size=0.2, random_state=42\n",")\n","\n","# Diccionario de modelos\n","modelos = {\n","    \"Regresi√≥n Lineal\": LinearRegression(),\n","    \"√Årbol de Decisi√≥n\": DecisionTreeRegressor(max_depth=5, random_state=42),\n","    \"Bosque Aleatorio\": RandomForestRegressor(n_estimators=100, random_state=42),\n","    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n","    \"SVM\": SVR(),\n","    \"K-Vecinos\": KNeighborsRegressor()\n","}\n","\n","# Lista para guardar los resultados\n","resultados = []\n","\n","# Evaluaci√≥n en bucle\n","for nombre, modelo in modelos.items():\n","    modelo.fit(X_train, y_train)\n","    y_pred = modelo.predict(X_test)\n","\n","    errores = {\n","        \"Modelo\": nombre,\n","        \"MAE\": mean_absolute_error(y_test, y_pred),\n","        \"MSE\": mean_squared_error(y_test, y_pred),\n","        \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n","        \"MedAE\": median_absolute_error(y_test, y_pred),\n","        \"Max Error\": max_error(y_test, y_pred),\n","        \"R2\": r2_score(y_test, y_pred)\n","    }\n","    resultados.append(errores)\n","\n","# Crear DataFrame ordenado por R¬≤\n","df_resultados = pd.DataFrame(resultados)\n","df_resultados = df_resultados.sort_values(by=\"R2\", ascending=False)\n","\n","# Mostrar\n","print(\"\\nüîé Resultados comparativos de todos los modelos:\\n\")\n","print(df_resultados.to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VU_MiAZ5uBbr","executionInfo":{"status":"ok","timestamp":1744037269146,"user_tz":180,"elapsed":44161,"user":{"displayName":"Hector Estigarribia FCyT UNCA","userId":"04796158545147043803"}},"outputId":"aa366d23-bdec-4154-b20c-1cce3561de67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üîé Resultados comparativos de todos los modelos:\n","\n","           Modelo      MAE      MSE     RMSE    MedAE  Max Error        R2\n"," Bosque Aleatorio 0.327543 0.255368 0.505340 0.201020   3.045841  0.805123\n","Gradient Boosting 0.371643 0.293997 0.542215 0.251555   4.011418  0.775645\n","√Årbol de Decisi√≥n 0.522259 0.524515 0.724234 0.381186   3.835414  0.599732\n"," Regresi√≥n Lineal 0.533200 0.555892 0.745581 0.410233   9.875331  0.575788\n","        K-Vecinos 0.812798 1.118682 1.057678 0.658200   3.892010  0.146310\n","              SVM 0.859951 1.332012 1.154128 0.661748   3.506065 -0.016485\n"]}]},{"cell_type":"markdown","source":["# Explicaci√≥n\n","Vamos a analizar tus resultados con una mirada comparativa y explicativa para entender **cu√°l modelo funciona mejor** y **por qu√©**. Te detallo cada m√©trica y lo que podemos concluir:\n","\n","---\n","\n","### üìä **Resumen del Rendimiento de Modelos**\n","\n","| Modelo               | R¬≤ Score ‚Üë | RMSE ‚Üì | MAE ‚Üì | Max Error ‚Üì |\n","|----------------------|------------|--------|-------|--------------|\n","| üåü **Bosque Aleatorio** | **0.805**  | **0.505** | **0.327** | ‚úÖ **3.05** |\n","| Gradient Boosting    | 0.776      | 0.542  | 0.372 | 4.01        |\n","| √Årbol de Decisi√≥n    | 0.600      | 0.724  | 0.522 | 3.83        |\n","| Regresi√≥n Lineal     | 0.576      | 0.746  | 0.533 | üî¥ 9.87      |\n","| K-Vecinos            | 0.146      | 1.058  | 0.813 | 3.89        |\n","| ‚ùå SVM               | **-0.016** | 1.154  | 0.860 | 3.50        |\n","\n","---\n","\n","### üß† ¬øQu√© significan las m√©tricas?\n","\n","- **R¬≤ (coeficiente de determinaci√≥n)**: entre 0 y 1 (idealmente cercano a 1). Indica qu√© tan bien el modelo explica la variabilidad de los datos. Negativo = peor que adivinar la media.\n","- **MAE (Error Absoluto Medio)**: Promedio del error absoluto. Intuitivo, f√°cil de interpretar.\n","- **MSE / RMSE**: Penalizan m√°s los errores grandes. RMSE tiene la misma unidad que la variable objetivo (precios en miles de d√≥lares).\n","- **MedAE**: Similar a MAE, pero menos sensible a *outliers*.\n","- **Max Error**: El peor caso en el test.\n","\n","---\n","\n","### ‚úÖ **Conclusiones**\n","\n","1. **üèÜ Bosque Aleatorio** es el claro ganador:\n","   - Mejor R¬≤ (0.805): explica m√°s del 80% de la variabilidad.\n","   - Menor MAE, MSE y RMSE ‚Üí errores m√°s bajos en promedio.\n","   - **Menor error m√°ximo** tambi√©n ‚Üí m√°s robusto.\n","\n","2. **Gradient Boosting** es muy competitivo, aunque ligeramente por detr√°s:\n","   - Casi mismo rendimiento, pero m√°s error m√°ximo.\n","\n","3. **√Årbol de Decisi√≥n y Regresi√≥n Lineal**:\n","   - Resultados aceptables, pero claramente superados por los ensambles (Random Forest, Gradient Boosting).\n","   - Regresi√≥n Lineal tiene un *max error* muy alto (9.8) ‚Üí un outlier muy mal predicho.\n","\n","4. **SVM y KNN**:\n","   - Mal rendimiento. R¬≤ negativo en SVM ‚Üí **predice peor que simplemente usar la media**.\n","   - Estos modelos suelen necesitar **m√°s ajuste de hiperpar√°metros** o **normalizaci√≥n de datos**.\n","\n","---"],"metadata":{"id":"0C7sImf2vGaC"}},{"cell_type":"markdown","source":["# Ejemplo para examen escrito"],"metadata":{"id":"8NnfHZejzHGe"}},{"cell_type":"code","source":["from sklearn.datasets import fetch_california_housing\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.svm import SVR\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, median_absolute_error, max_error, r2_score\n","\n","# Cargar dataset\n","dataset = fetch_california_housing()\n","X = dataset.data\n","y = dataset.target\n","df = pd.DataFrame(X, columns=dataset.feature_names)\n","df[\"MEDV\"] = y\n","\n","# Imprimir estructura y estad√≠sticas\n","print(df.shape)\n","for col in df.columns:\n","    print(col)\n","for col in df.columns:\n","    print(df[col].nunique())\n","print(df.describe().round(2))\n","\n","# Separar features y target\n","X = df.drop(columns=[\"MEDV\"])\n","y = df[\"MEDV\"]\n","\n","# Dividir conjuntos\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(X_train.shape)\n","print(X_test.shape)\n","print(y_train.shape)\n","print(y_test.shape)\n","\n","# Modelos\n","modelos = [\n","    LinearRegression(),\n","    DecisionTreeRegressor(max_depth=5, random_state=42),\n","    RandomForestRegressor(n_estimators=100, random_state=42),\n","    GradientBoostingRegressor(n_estimators=100, random_state=42),\n","    SVR(),\n","    KNeighborsRegressor()\n","]\n","\n","# Evaluaci√≥n de cada modelo\n","for modelo in modelos:\n","    modelo.fit(X_train, y_train)\n","    y_pred = modelo.predict(X_test)\n","    print(round(mean_absolute_error(y_test, y_pred), 6))\n","    print(round(mean_squared_error(y_test, y_pred), 6))\n","    print(round(np.sqrt(mean_squared_error(y_test, y_pred)), 6))\n","    print(round(median_absolute_error(y_test, y_pred), 6))\n","    print(round(max_error(y_test, y_pred), 6))\n","    print(round(r2_score(y_test, y_pred), 6))\n","    # imprime una linea horizontal\n","    print(\"-\" * 50)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h-0EnwicxSUT","executionInfo":{"status":"ok","timestamp":1744050457109,"user_tz":180,"elapsed":43389,"user":{"displayName":"Hector Estigarribia FCyT UNCA","userId":"04796158545147043803"}},"outputId":"6674a3e7-a0a2-4dd6-b00c-46f00b940af1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(20640, 9)\n","MedInc\n","HouseAge\n","AveRooms\n","AveBedrms\n","Population\n","AveOccup\n","Latitude\n","Longitude\n","MEDV\n","12928\n","52\n","19392\n","14233\n","3888\n","18841\n","862\n","844\n","3842\n","         MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n","count  20640.00  20640.00  20640.00   20640.00    20640.00  20640.00   \n","mean       3.87     28.64      5.43       1.10     1425.48      3.07   \n","std        1.90     12.59      2.47       0.47     1132.46     10.39   \n","min        0.50      1.00      0.85       0.33        3.00      0.69   \n","25%        2.56     18.00      4.44       1.01      787.00      2.43   \n","50%        3.53     29.00      5.23       1.05     1166.00      2.82   \n","75%        4.74     37.00      6.05       1.10     1725.00      3.28   \n","max       15.00     52.00    141.91      34.07    35682.00   1243.33   \n","\n","       Latitude  Longitude      MEDV  \n","count  20640.00   20640.00  20640.00  \n","mean      35.63    -119.57      2.07  \n","std        2.14       2.00      1.15  \n","min       32.54    -124.35      0.15  \n","25%       33.93    -121.80      1.20  \n","50%       34.26    -118.49      1.80  \n","75%       37.71    -118.01      2.65  \n","max       41.95    -114.31      5.00  \n","(16512, 8)\n","(4128, 8)\n","(16512,)\n","(4128,)\n","0.5332\n","0.555892\n","0.745581\n","0.410233\n","9.875331\n","0.575788\n","--------------------------------------------------\n","0.522259\n","0.524515\n","0.724234\n","0.381186\n","3.835414\n","0.599732\n","--------------------------------------------------\n","0.327543\n","0.255368\n","0.50534\n","0.20102\n","3.045841\n","0.805123\n","--------------------------------------------------\n","0.371643\n","0.293997\n","0.542215\n","0.251555\n","4.011418\n","0.775645\n","--------------------------------------------------\n","0.859951\n","1.332012\n","1.154128\n","0.661748\n","3.506065\n","-0.016485\n","--------------------------------------------------\n","0.812798\n","1.118682\n","1.057678\n","0.6582\n","3.89201\n","0.14631\n","--------------------------------------------------\n"]}]}]}