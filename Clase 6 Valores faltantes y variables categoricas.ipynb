{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyO+HK8vgtSUs4ZQ63sgE1gO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Л Introducci贸n\n","\n","En esta pr谩ctica trabajaremos con el dataset real **Titanic**, muy utilizado en ciencia de datos por su riqueza y variedad de variables. A diferencia de los datasets anteriores, este contiene:\n","\n","- **Campos vac铆os (valores faltantes)** en varias columnas.\n","- **Variables categ贸ricas**, como nombres, g茅nero, clases del pasaje, entre otras.\n","- Mezcla de **datos num茅ricos y no num茅ricos**, lo que requiere un preprocesamiento m谩s cuidadoso.\n","\n","El objetivo de esta actividad es practicar conceptos fundamentales del tratamiento de datos reales antes del entrenamiento de modelos:\n","\n","-  Identificar y tratar **valores faltantes**\n","-  Codificar **variables categ贸ricas** (label encoding, one-hot encoding)\n","- Ч Preparar un conjunto de datos limpio, num茅rico y listo para aplicar modelos de machine learning\n","\n","Este paso es clave en cualquier proyecto de ciencia de datos y nos permite adaptar los datos a las exigencias de los algoritmos de aprendizaje autom谩tico.\n","\n","---\n"],"metadata":{"id":"GOHEr_P_cSip"}},{"cell_type":"markdown","source":["#  Paso 1: Carga del dataset Titanic\n"," El dataset \"Titanic\" contiene informaci贸n sobre los pasajeros del famoso barco. Es 煤til para tareas de clasificaci贸n: por ejemplo, predecir qui茅n sobrevivi贸 (survived)."],"metadata":{"id":"8ie-pH57eqpA"}},{"cell_type":"code","source":["#  Cargar el dataset Titanic desde seaborn y explorar su contenido\n","import seaborn as sns\n","import pandas as pd\n","\n","# Cargar el dataset como un DataFrame\n","df = sns.load_dataset(\"titanic\")\n","\n","# Mostrar las primeras 5 filas\n","print(\"Primeras filas: \",  \"\\n\", df.head(),  \"\\n\") # El '\\n' representa un salto de l铆nea\n","\n","# Mostrar la forma del dataset (filas, columnas)\n","print(\"Filas y columnas: \", df.shape,  \"\\n\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1wsWlUncX65","executionInfo":{"status":"ok","timestamp":1744639289649,"user_tz":180,"elapsed":54,"user":{"displayName":"Hector Estigarribia FCyT UNCA","userId":"04796158545147043803"}},"outputId":"fe250eea-64c6-4e88-f831-7ba3a4de59ad"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Primeras filas:  \n","    survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n","0         0       3    male  22.0      1      0   7.2500        S  Third   \n","1         1       1  female  38.0      1      0  71.2833        C  First   \n","2         1       3  female  26.0      0      0   7.9250        S  Third   \n","3         1       1  female  35.0      1      0  53.1000        S  First   \n","4         0       3    male  35.0      0      0   8.0500        S  Third   \n","\n","     who  adult_male deck  embark_town alive  alone  \n","0    man        True  NaN  Southampton    no  False  \n","1  woman       False    C    Cherbourg   yes  False  \n","2  woman       False  NaN  Southampton   yes   True  \n","3  woman       False    C  Southampton   yes  False  \n","4    man        True  NaN  Southampton    no   True   \n","\n","Filas y columnas:  (891, 15) \n","\n"]}]},{"cell_type":"code","source":["# Informaci贸n general de columnas, tipos y valores faltantes\n","print(\"Informaci贸n general:\", \"\\n\")\n","print( df.info(),  \"\\n\")\n","\n","# Estad铆sticas descriptivas de columnas num茅ricas\n","print(\"Estad铆sticas descriptivas de columnas num茅ricas: \", \"\\n\", df.describe())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CgvivuUXmIJE","executionInfo":{"status":"ok","timestamp":1744639263426,"user_tz":180,"elapsed":17,"user":{"displayName":"Hector Estigarribia FCyT UNCA","userId":"04796158545147043803"}},"outputId":"5bc94b8e-3a6c-4918-d5f7-8f5e9244b8a0"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Informaci贸n general: \n","\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 891 entries, 0 to 890\n","Data columns (total 15 columns):\n"," #   Column       Non-Null Count  Dtype   \n","---  ------       --------------  -----   \n"," 0   survived     891 non-null    int64   \n"," 1   pclass       891 non-null    int64   \n"," 2   sex          891 non-null    object  \n"," 3   age          714 non-null    float64 \n"," 4   sibsp        891 non-null    int64   \n"," 5   parch        891 non-null    int64   \n"," 6   fare         891 non-null    float64 \n"," 7   embarked     889 non-null    object  \n"," 8   class        891 non-null    category\n"," 9   who          891 non-null    object  \n"," 10  adult_male   891 non-null    bool    \n"," 11  deck         203 non-null    category\n"," 12  embark_town  889 non-null    object  \n"," 13  alive        891 non-null    object  \n"," 14  alone        891 non-null    bool    \n","dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n","memory usage: 80.7+ KB\n","None \n","\n","Estad铆sticas descriptivas de columnas num茅ricas:  \n","          survived      pclass         age       sibsp       parch        fare\n","count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n","mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n","std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n","min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n","25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n","50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n","75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n","max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"]}]},{"cell_type":"markdown","source":["---\n","\n","# **An谩lisis de la Informaci贸n General del DataFrame**\n","\n","El resultado de la funci贸n `df.info()` nos proporciona una visi贸n general crucial de nuestro conjunto de datos, y en este caso, revela aspectos importantes que no hab铆amos encontrado en nuestros ejemplos anteriores con datos puramente num茅ricos y completos.\n","\n","En primer lugar, vemos que tenemos un DataFrame con **891 entradas (filas)**, indexadas desde 0 hasta 890. Esto representa el n煤mero total de observaciones en nuestro conjunto de datos.\n","\n","A continuaci贸n, se detalla la informaci贸n de cada una de las **15 columnas**. Para cada columna, observamos dos aspectos fundamentales:\n","\n","* **`Non-Null Count` (Conteo de Valores No Nulos):** Esta columna nos indica cu谩ntos valores **no faltantes** hay en cada una de las columnas. Aqu铆 es donde encontramos una novedad importante: **algunas columnas tienen menos de 891 valores no nulos**. Espec铆ficamente, notamos que la columna `age` tiene solo 714 valores no nulos, y la columna `embarked` y `embark_town` tienen 889. La columna m谩s llamativa es `deck`, con tan solo 203 valores no nulos. **Esto significa que tenemos datos faltantes en estas columnas.** En un contexto de Machine Learning, los datos faltantes son un desaf铆o que debemos abordar, ya que muchos algoritmos no pueden trabajar directamente con ellos. Necesitaremos aplicar t茅cnicas de **imputaci贸n** (reemplazar los valores faltantes con alg煤n valor estimado) o considerar eliminar las columnas o filas con demasiados faltantes, dependiendo del contexto y del impacto en nuestro modelo.\n","\n","* **`Dtype` (Tipo de Dato):** Esta columna nos muestra el tipo de dato que contiene cada columna. Aqu铆 tambi茅n encontramos novedades importantes con respecto a nuestros conjuntos de datos anteriores:\n","    * **`object`:** Varias columnas como `sex`, `embarked`, `who`, `embark_town`, y `alive` son de tipo `object`. Esto generalmente indica que contienen **cadenas de texto (strings)**. Los algoritmos de Machine Learning, en su mayor铆a, trabajan con datos num茅ricos. Por lo tanto, necesitaremos aplicar t茅cnicas de **codificaci贸n (encoding)** para convertir estas variables categ贸ricas en representaciones num茅ricas que los modelos puedan entender.\n","    * **`category`:** Las columnas `class` y `deck` son de tipo `category`. Este es un tipo de dato eficiente para variables categ贸ricas con un n煤mero limitado de valores distintos. Internamente, Pandas representa estas categor铆as con n煤meros, lo que puede ser beneficioso para la memoria y la velocidad. Sin embargo, al igual que con las columnas `object`, es posible que necesitemos considerar c贸mo se interpretan estas categor铆as en nuestros modelos de ML.\n","    * **`bool`:** Las columnas `adult_male` y `alone` son de tipo booleano, representando valores True o False. Muchos algoritmos pueden trabajar directamente con datos booleanos, interpret谩ndolos como 0 y 1.\n","    * **`int64` y `float64`:** Estas son columnas num茅ricas, como las que ya hemos trabajado (`survived`, `pclass`, `sibsp`, `parch`, `fare`, `age`). `int64` representa n煤meros enteros, mientras que `float64` representa n煤meros de punto flotante.\n","\n","Finalmente, la secci贸n de **`memory usage`** nos indica la cantidad de memoria que est谩 utilizando este DataFrame. Esto puede ser importante cuando trabajamos con conjuntos de datos muy grandes.\n","\n","El 煤ltimo `None` que aparece es el valor de retorno de la funci贸n `df.info()`, que en Python es `None` ya que su prop贸sito principal es imprimir la informaci贸n, no devolver un objeto.\n","\n","**En resumen, al enfrentarnos a este nuevo conjunto de datos, debemos prestar especial atenci贸n a:**\n","\n","1.  **Los valores faltantes:** Identificar las columnas afectadas y decidir la estrategia para manejarlos.\n","2.  **Los tipos de datos no num茅ricos (`object` y `category`):** Planificar c贸mo vamos a codificar estas variables para que puedan ser utilizadas por nuestros modelos de Machine Learning.\n","\n","Estos son pasos cruciales en el preprocesamiento de datos para construir modelos efectivos, especialmente cuando trabajamos con datos del mundo real que rara vez son perfectos y puramente num茅ricos.\n","\n","---"],"metadata":{"id":"vBksgUsxoPOD"}},{"cell_type":"markdown","source":["\n","---\n","\n","# ** Paso 2: Un Primer Modelo Simplificado - Eliminaci贸n de Datos No Num茅ricos y Faltantes**\n","\n","En este segundo paso, vamos a realizar un ciclo completo de Machine Learning: divisi贸n del dataset, entrenamiento de un modelo, realizaci贸n de predicciones y evaluaci贸n de su rendimiento. Sin embargo, para simplificar este primer ejercicio y enfocarnos en el flujo general, vamos a tomar un atajo para lidiar con las columnas que no son num茅ricas y las filas que contienen valores faltantes.\n","\n","**Importante:** Esta es una estrategia simplificada y **no es la mejor pr谩ctica** en la mayor铆a de los escenarios reales. Eliminar columnas enteras con informaci贸n potencialmente 煤til y filas con datos faltantes puede llevar a una p茅rdida significativa de informaci贸n y a un modelo sub贸ptimo. En pasos posteriores, exploraremos t茅cnicas m谩s sofisticadas para manejar estos problemas.\n","\n","En este paso, nuestro objetivo principal es tener un primer modelo funcional, aunque sea basado en una versi贸n reducida de nuestros datos. Para ello, realizaremos las siguientes acciones:\n","\n","1.  **Identificar y eliminar las columnas no num茅ricas:** Seleccionaremos solo las columnas con tipos de datos num茅ricos (enteros y flotantes) para poder alimentar directamente nuestro modelo.\n","2.  **Eliminar las filas con valores faltantes (NaN):** Removeremos cualquier fila que contenga al menos un valor faltante en cualquiera de las columnas restantes.\n","\n","Una vez que tengamos un dataset limpio (aunque reducido), procederemos con los pasos habituales:\n","\n","1.  **Dividir el dataset** en un conjunto de entrenamiento y un conjunto de prueba.\n","2.  **Seleccionar y entrenar un modelo de clasificaci贸n.** Para este primer ejemplo, utilizaremos un modelo simple como la Regresi贸n Log铆stica.\n","3.  **Realizar predicciones** sobre el conjunto de prueba.\n","4.  **Evaluar el rendimiento** del modelo utilizando una m茅trica adecuada para la clasificaci贸n, como la exactitud (accuracy).\n","\n","Este proceso nos dar谩 una primera idea del flujo de trabajo completo en un problema de clasificaci贸n, aunque con las limitaciones impuestas por nuestra estrategia simplificada de manejo de datos.\n","\n","---\n","\n","Aqu铆 tienes el c贸digo en Google Colab para llevar a cabo estos pasos:"],"metadata":{"id":"znqeD9QWqQg9"}},{"cell_type":"code","source":["\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","# Asumiendo que 'df' es tu DataFrame cargado en el Paso 1\n","\n","# 1. Seleccionar solo las columnas num茅ricas\n","df_numeric = df.select_dtypes(include=['int64', 'float64'])\n","print(\"DataFrame solo con columnas num茅ricas:\")\n","print(df_numeric.head())\n","print(\"\\nForma del DataFrame num茅rico:\", df_numeric.shape)\n","\n","# 2. Eliminar las filas con valores faltantes\n","df_cleaned = df_numeric.dropna()\n","print(\"\\nDataFrame despu茅s de eliminar filas con NaN:\")\n","print(df_cleaned.head())\n","print(\"\\nForma del DataFrame limpio:\", df_cleaned.shape)\n","\n","# 3. Definir las variables predictoras (X) y la variable objetivo (y)\n","X = df_cleaned.drop('survived', axis=1)\n","y = df_cleaned['survived']\n","\n","# 4. Dividir el dataset en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(\"\\nForma de X_train:\", X_train.shape)\n","print(\"Forma de X_test:\", X_test.shape)\n","print(\"Forma de y_train:\", y_train.shape)\n","print(\"Forma de y_test:\", y_test.shape)\n","\n","# 5. Inicializar y entrenar un modelo de Regresi贸n Log铆stica\n","model = LogisticRegression(solver='liblinear', random_state=42)\n","model.fit(X_train, y_train)\n","\n","# 6. Realizar predicciones en el conjunto de prueba\n","y_pred = model.predict(X_test)\n","\n","# 7. Evaluar el rendimiento del modelo\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"\\nExactitud del modelo en el conjunto de prueba:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"187mP8mVqWbD","executionInfo":{"status":"ok","timestamp":1744640396265,"user_tz":180,"elapsed":31,"user":{"displayName":"Hector Estigarribia FCyT UNCA","userId":"04796158545147043803"}},"outputId":"3bab5743-c288-40aa-8dbb-d9acfcae8e2e"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["DataFrame solo con columnas num茅ricas:\n","   survived  pclass   age  sibsp  parch     fare\n","0         0       3  22.0      1      0   7.2500\n","1         1       1  38.0      1      0  71.2833\n","2         1       3  26.0      0      0   7.9250\n","3         1       1  35.0      1      0  53.1000\n","4         0       3  35.0      0      0   8.0500\n","\n","Forma del DataFrame num茅rico: (891, 6)\n","\n","DataFrame despu茅s de eliminar filas con NaN:\n","   survived  pclass   age  sibsp  parch     fare\n","0         0       3  22.0      1      0   7.2500\n","1         1       1  38.0      1      0  71.2833\n","2         1       3  26.0      0      0   7.9250\n","3         1       1  35.0      1      0  53.1000\n","4         0       3  35.0      0      0   8.0500\n","\n","Forma del DataFrame limpio: (714, 6)\n","\n","Forma de X_train: (571, 5)\n","Forma de X_test: (143, 5)\n","Forma de y_train: (571,)\n","Forma de y_test: (143,)\n","\n","Exactitud del modelo en el conjunto de prueba: 0.7062937062937062\n"]}]},{"cell_type":"markdown","source":["\n","# Explicaci贸n del C贸digo Paso 2:\n","\n","* **`df.select_dtypes(include=['int64', 'float64'])`:** Selecciona del DataFrame original (`df`) solo las columnas cuyos tipos de datos son enteros de 64 bits (`int64`) o n煤meros de punto flotante de 64 bits (`float64`).\n","* **`df_numeric.dropna()`:** Crea un nuevo DataFrame (`df_cleaned`) eliminando todas las filas que contengan al menos un valor `NaN` (Not a Number) en cualquiera de las columnas.\n","* **Definici贸n de `X` e `y`:** Asumimos que la columna `'survived'` es nuestra variable objetivo (la que queremos predecir). Separamos las caracter铆sticas predictoras (`X`) eliminando la columna objetivo y la variable objetivo (`y`). **Si tu objetivo es diferente, aseg煤rate de ajustar el nombre de la columna.**\n","* **`train_test_split()`:** Divide nuestros datos limpios en un conjunto de entrenamiento (80%) y un conjunto de prueba (20%). `random_state` se utiliza para asegurar la reproducibilidad de la divisi贸n.\n","* **`LogisticRegression()`:** Inicializamos un modelo de Regresi贸n Log铆stica. El argumento `solver='liblinear'` es una buena opci贸n para datasets peque帽os o medianos.\n","* **`model.fit(X_train, y_train)`:** Entrenamos el modelo utilizando el conjunto de entrenamiento. El modelo aprende la relaci贸n entre las caracter铆sticas en `X_train` y la variable objetivo en `y_train`.\n","* **`model.predict(X_test)`:** Utilizamos el modelo entrenado para hacer predicciones sobre el conjunto de prueba (`X_test`).\n","* **`accuracy_score(y_test, y_pred)`:** Comparamos las predicciones del modelo (`y_pred`) con los valores reales de la variable objetivo en el conjunto de prueba (`y_test`) para calcular la exactitud, que es el porcentaje de predicciones correctas."],"metadata":{"id":"Qw8XdDD_qfY5"}},{"cell_type":"markdown","source":["---\n","\n","# ** Paso 3: Imputaci贸n y Codificaci贸n para un Mejor Preprocesamiento**\n","*En este Paso, vamos a abordar de manera m谩s adecuada los desaf铆os de los datos no num茅ricos y los valores faltantes. En lugar de simplemente eliminarlos, aplicaremos t茅cnicas de **imputaci贸n** para rellenar los valores faltantes y de **codificaci贸n** para convertir las variables categ贸ricas en un formato num茅rico que nuestros modelos puedan entender.*\n","\n","En el paso anterior, realizamos un ciclo completo de Machine Learning de forma simplificada, eliminando informaci贸n valiosa al descartar columnas no num茅ricas y filas con datos faltantes. En este Paso 3, vamos a mejorar significativamente nuestro preprocesamiento de datos aplicando t茅cnicas m谩s sofisticadas:\n","\n","1.  **Imputaci贸n de Valores Faltantes:** Para las columnas que contienen valores `NaN`, utilizaremos estrategias para estimar y reemplazar estos valores faltantes. La elecci贸n de la estrategia de imputaci贸n depender谩 del tipo de dato de la columna y de la naturaleza de los datos. Algunas estrategias comunes incluyen:\n","    * Para columnas num茅ricas: Imputar con la media, la mediana o un valor constante.\n","    * Para columnas categ贸ricas: Imputar con la moda (el valor m谩s frecuente) o una nueva categor铆a como \"Desconocido\".\n","\n","2.  **Codificaci贸n de Variables Categ贸ricas:** Las columnas con tipos de datos `object` o `category` contienen informaci贸n categ贸rica que la mayor铆a de los algoritmos de Machine Learning no pueden procesar directamente. Necesitamos convertirlas a un formato num茅rico. Algunas t茅cnicas comunes de codificaci贸n son:\n","    * **One-Hot Encoding:** Crea nuevas columnas binarias (0 o 1) para cada categor铆a 煤nica en la variable original. Es 煤til cuando las categor铆as no tienen un orden inherente.\n","    * **Label Encoding:** Asigna un n煤mero entero 煤nico a cada categor铆a. Es apropiado para variables ordinales (donde las categor铆as tienen un orden).\n","\n","Nuestro objetivo en este paso es preparar un dataset m谩s completo y representativo para el entrenamiento de modelos, reteniendo la informaci贸n valiosa que descartamos en el paso anterior. Luego, como hicimos antes, dividiremos el dataset preprocesado, entrenaremos un modelo y lo evaluaremos.\n","\n","---\n","\n","Aqu铆 tienes el c贸digo en Google Colab para realizar la imputaci贸n y la codificaci贸n. Vamos a aplicar estrategias comunes, pero recuerda que la elecci贸n de la mejor estrategia a menudo requiere un an谩lisis m谩s profundo de los datos.\n"],"metadata":{"id":"9S5syFtOr61y"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# Asumiendo que 'df' es tu DataFrame cargado en el Paso 1\n","\n","# 1. Separar la variable objetivo\n","X = df.drop('survived', axis=1)\n","y = df['survived']\n","\n","# 2. Identificar columnas num茅ricas y categ贸ricas\n","numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n","categorical_cols = X.select_dtypes(include=['object', 'category', 'bool']).columns\n","\n","# 3. Imputar valores faltantes\n","# Imputaci贸n num茅rica con la media\n","numerical_imputer = SimpleImputer(strategy='mean')\n","X[numerical_cols] = numerical_imputer.fit_transform(X[numerical_cols])\n","\n","# Imputaci贸n categ贸rica con la moda\n","categorical_imputer = SimpleImputer(strategy='most_frequent')\n","X[categorical_cols] = categorical_imputer.fit_transform(X[categorical_cols])\n","\n","print(\"DataFrame despu茅s de la imputaci贸n:\")\n","print(X.head())\n","print(\"\\nValores nulos despu茅s de la imputaci贸n:\")\n","print(X.isnull().sum())\n","\n","# 4. Codificar variables categ贸ricas usando One-Hot Encoding\n","encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False) # sparse=False para obtener un array NumPy\n","X_encoded = encoder.fit_transform(X[categorical_cols])\n","feature_names = encoder.get_feature_names_out(categorical_cols)\n","X_encoded_df = pd.DataFrame(X_encoded, index=X.index, columns=feature_names)\n","\n","# Concatenar las columnas num茅ricas con las columnas codificadas\n","X_processed = pd.concat([X[numerical_cols], X_encoded_df], axis=1)\n","\n","print(\"\\nDataFrame despu茅s del One-Hot Encoding:\")\n","print(X_processed.head())\n","print(\"\\nForma del DataFrame preprocesado:\", X_processed.shape)\n","\n","# 5. Dividir los datos en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n","\n","print(\"\\nForma de X_train:\", X_train.shape)\n","print(\"Forma de X_test:\", X_test.shape)\n","print(\"Forma de y_train:\", y_train.shape)\n","print(\"Forma de y_test:\", y_test.shape)\n","\n","# 6. Inicializar y entrenar un modelo de Regresi贸n Log铆stica\n","model = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000)\n","model.fit(X_train, y_train)\n","\n","# 7. Realizar predicciones en el conjunto de prueba\n","y_pred = model.predict(X_test)\n","\n","# 8. Evaluar el rendimiento del modelo\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"\\nExactitud del modelo en el conjunto de prueba (con imputaci贸n y codificaci贸n simplificadas):\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NQORdBnDsZNJ","executionInfo":{"status":"ok","timestamp":1744641160071,"user_tz":180,"elapsed":260,"user":{"displayName":"Hector Estigarribia FCyT UNCA","userId":"04796158545147043803"}},"outputId":"6b29ea5d-b984-48b0-e440-3b3d09f39553"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["DataFrame despu茅s de la imputaci贸n:\n","   pclass     sex   age  sibsp  parch     fare embarked  class    who  \\\n","0     3.0    male  22.0    1.0    0.0   7.2500        S  Third    man   \n","1     1.0  female  38.0    1.0    0.0  71.2833        C  First  woman   \n","2     3.0  female  26.0    0.0    0.0   7.9250        S  Third  woman   \n","3     1.0  female  35.0    1.0    0.0  53.1000        S  First  woman   \n","4     3.0    male  35.0    0.0    0.0   8.0500        S  Third    man   \n","\n","  adult_male deck  embark_town alive  alone  \n","0       True    C  Southampton    no  False  \n","1      False    C    Cherbourg   yes  False  \n","2      False    C  Southampton   yes   True  \n","3      False    C  Southampton   yes  False  \n","4       True    C  Southampton    no   True  \n","\n","Valores nulos despu茅s de la imputaci贸n:\n","pclass         0\n","sex            0\n","age            0\n","sibsp          0\n","parch          0\n","fare           0\n","embarked       0\n","class          0\n","who            0\n","adult_male     0\n","deck           0\n","embark_town    0\n","alive          0\n","alone          0\n","dtype: int64\n","\n","DataFrame despu茅s del One-Hot Encoding:\n","   pclass   age  sibsp  parch     fare  sex_female  sex_male  embarked_C  \\\n","0     3.0  22.0    1.0    0.0   7.2500         0.0       1.0         0.0   \n","1     1.0  38.0    1.0    0.0  71.2833         1.0       0.0         1.0   \n","2     3.0  26.0    0.0    0.0   7.9250         1.0       0.0         0.0   \n","3     1.0  35.0    1.0    0.0  53.1000         1.0       0.0         0.0   \n","4     3.0  35.0    0.0    0.0   8.0500         0.0       1.0         0.0   \n","\n","   embarked_Q  embarked_S  ...  deck_E  deck_F  deck_G  embark_town_Cherbourg  \\\n","0         0.0         1.0  ...     0.0     0.0     0.0                    0.0   \n","1         0.0         0.0  ...     0.0     0.0     0.0                    1.0   \n","2         0.0         1.0  ...     0.0     0.0     0.0                    0.0   \n","3         0.0         1.0  ...     0.0     0.0     0.0                    0.0   \n","4         0.0         1.0  ...     0.0     0.0     0.0                    0.0   \n","\n","   embark_town_Queenstown  embark_town_Southampton  alive_no  alive_yes  \\\n","0                     0.0                      1.0       1.0        0.0   \n","1                     0.0                      0.0       0.0        1.0   \n","2                     0.0                      1.0       0.0        1.0   \n","3                     0.0                      1.0       0.0        1.0   \n","4                     0.0                      1.0       1.0        0.0   \n","\n","   alone_False  alone_True  \n","0          1.0         0.0  \n","1          1.0         0.0  \n","2          0.0         1.0  \n","3          1.0         0.0  \n","4          0.0         1.0  \n","\n","[5 rows x 32 columns]\n","\n","Forma del DataFrame preprocesado: (891, 32)\n","\n","Forma de X_train: (712, 32)\n","Forma de X_test: (179, 32)\n","Forma de y_train: (712,)\n","Forma de y_test: (179,)\n","\n","Exactitud del modelo en el conjunto de prueba (con imputaci贸n y codificaci贸n simplificadas): 1.0\n"]}]},{"cell_type":"markdown","source":["\n","---\n","\n","# Explicaci贸n del c贸digo Paso 3\n","\n","Este c贸digo representa un flujo de trabajo fundamental en Machine Learning, que incluye la preparaci贸n de los datos (preprocesamiento) y el entrenamiento de un modelo de clasificaci贸n. Vamos a desglosar cada secci贸n:\n","\n","**1. Importaci贸n de Librer铆as Necesarias:**\n","\n","```python\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder\n","```\n","\n","* **`import pandas as pd`**: Importa la librer铆a Pandas, que es esencial para trabajar con estructuras de datos tabulares como los DataFrames. Usaremos `pd` como un alias para referirnos a ella de forma m谩s concisa.\n","* **`from sklearn.model_selection import train_test_split`**: Importa la funci贸n `train_test_split` de la librer铆a Scikit-learn (`sklearn`). Esta funci贸n nos permitir谩 dividir nuestro conjunto de datos en dos partes: un conjunto para entrenar nuestro modelo y otro para evaluar su rendimiento.\n","* **`from sklearn.linear_model import LogisticRegression`**: Importa el modelo de clasificaci贸n de Regresi贸n Log铆stica de Scikit-learn. Este es un algoritmo que se utiliza para problemas de clasificaci贸n binaria (en nuestro caso, predecir si un pasajero sobrevivi贸 o no).\n","* **`from sklearn.metrics import accuracy_score`**: Importa la funci贸n `accuracy_score` de Scikit-learn. La exactitud es una m茅trica que nos dice qu茅 porcentaje de las predicciones de nuestro modelo fueron correctas.\n","* **`from sklearn.impute import SimpleImputer`**: Importa la clase `SimpleImputer` de Scikit-learn. Esta herramienta nos ayudar谩 a manejar los valores faltantes (NaN) en nuestros datos, reemplaz谩ndolos con una estrategia espec铆fica (como la media o la moda).\n","* **`from sklearn.preprocessing import OneHotEncoder`**: Importa la clase `OneHotEncoder` de Scikit-learn. Esta t茅cnica se utiliza para convertir variables categ贸ricas (textuales o con un n煤mero limitado de categor铆as) en un formato num茅rico que los algoritmos de Machine Learning pueden entender.\n","\n","**2. Separaci贸n de la Variable Objetivo y las Caracter铆sticas:**\n","\n","```python\n","# Asumiendo que 'df' es tu DataFrame cargado en el Paso 1\n","\n","# 1. Separar la variable objetivo\n","X = df.drop('survived', axis=1)\n","y = df['survived']\n","```\n","\n","* Asumimos que `df` es el DataFrame que cargamos y analizamos en el Paso 1.\n","* **`X = df.drop('survived', axis=1)`**: Creamos un nuevo DataFrame llamado `X` que contiene todas las columnas del DataFrame original `df`, **excepto** la columna `'survived'`. Consideramos las columnas en `X` como las **caracter铆sticas predictoras** o variables independientes que usaremos para predecir la variable objetivo. El argumento `axis=1` indica que queremos eliminar una columna.\n","* **`y = df['survived']`**: Creamos una Serie de Pandas llamada `y` que contiene **solo** la columna `'survived'` del DataFrame original. Esta es nuestra **variable objetivo** o variable dependiente, la cual queremos predecir con nuestro modelo.\n","\n","**3. Identificaci贸n de Tipos de Columnas:**\n","\n","```python\n","# 2. Identificar columnas num茅ricas y categ贸ricas\n","numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n","categorical_cols = X.select_dtypes(include=['object', 'category', 'bool']).columns\n","```\n","\n","* Para aplicar diferentes estrategias de preprocesamiento a diferentes tipos de datos, primero identificamos las columnas num茅ricas y categ贸ricas en nuestro conjunto de caracter铆sticas `X`.\n","* **`numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns`**: Selecciona todas las columnas en `X` cuyo tipo de dato es entero (`int64`) o n煤mero de punto flotante (`float64`) y guarda sus nombres en la lista `numerical_cols`.\n","* **`categorical_cols = X.select_dtypes(include=['object', 'category', 'bool']).columns`**: Selecciona todas las columnas en `X` cuyo tipo de dato es objeto (generalmente texto), categor铆a o booleano, y guarda sus nombres en la lista `categorical_cols`.\n","\n","**4. Imputaci贸n de Valores Faltantes:**\n","\n","```python\n","# 3. Imputar valores faltantes\n","# Imputaci贸n num茅rica con la media\n","numerical_imputer = SimpleImputer(strategy='mean')\n","X[numerical_cols] = numerical_imputer.fit_transform(X[numerical_cols])\n","\n","# Imputaci贸n categ贸rica con la moda\n","categorical_imputer = SimpleImputer(strategy='most_frequent')\n","X[categorical_cols] = categorical_imputer.fit_transform(X[categorical_cols])\n","\n","print(\"DataFrame despu茅s de la imputaci贸n:\")\n","print(X.head())\n","print(\"\\nValores nulos despu茅s de la imputaci贸n:\")\n","print(X.isnull().sum())\n","```\n","\n","* Aqu铆 manejamos los valores faltantes (NaN) que pudimos haber identificado en el Paso 1.\n","* **`numerical_imputer = SimpleImputer(strategy='mean')`**: Creamos un objeto `SimpleImputer` para las columnas num茅ricas. La estrategia `'mean'` indica que los valores faltantes en estas columnas ser谩n reemplazados por la media de los valores existentes en cada columna.\n","* **`X[numerical_cols] = numerical_imputer.fit_transform(X[numerical_cols])`**: Primero, `fit_transform` calcula la media de cada columna num茅rica en `X` y luego reemplaza los valores faltantes en esas mismas columnas con sus respectivas medias. El resultado se asigna de nuevo a las columnas num茅ricas de `X`, modificando el DataFrame.\n","* **`categorical_imputer = SimpleImputer(strategy='most_frequent')`**: Creamos otro `SimpleImputer` para las columnas categ贸ricas. La estrategia `'most_frequent'` indica que los valores faltantes en estas columnas ser谩n reemplazados por la moda (el valor que aparece con mayor frecuencia) en cada columna.\n","* **`X[categorical_cols] = categorical_imputer.fit_transform(X[categorical_cols])`**: De manera similar, `fit_transform` calcula la moda de cada columna categ贸rica en `X` y luego reemplaza los valores faltantes con sus respectivas modas. El resultado se asigna de vuelta a las columnas categ贸ricas de `X`.\n","* Las siguientes l铆neas de `print` muestran las primeras filas del DataFrame despu茅s de la imputaci贸n y la cantidad de valores nulos por columna, lo que deber铆a confirmar que ya no tenemos valores faltantes.\n","\n","**5. Codificaci贸n de Variables Categ贸ricas (One-Hot Encoding):**\n","\n","```python\n","# 4. Codificar variables categ贸ricas usando One-Hot Encoding\n","encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False) # sparse=False para obtener un array NumPy\n","X_encoded = encoder.fit_transform(X[categorical_cols])\n","feature_names = encoder.get_feature_names_out(categorical_cols)\n","X_encoded_df = pd.DataFrame(X_encoded, index=X.index, columns=feature_names)\n","\n","# Concatenar las columnas num茅ricas con las columnas codificadas\n","X_processed = pd.concat([X[numerical_cols], X_encoded_df], axis=1)\n","\n","print(\"\\nDataFrame despu茅s del One-Hot Encoding:\")\n","print(X_processed.head())\n","print(\"\\nForma del DataFrame preprocesado:\", X_processed.shape)\n","```\n","\n","* Aqu铆 convertimos las variables categ贸ricas en un formato num茅rico adecuado para nuestro modelo de Regresi贸n Log铆stica.\n","* **`encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)`**: Creamos un objeto `OneHotEncoder`.\n","    * `handle_unknown='ignore'` le dice al encoder que ignore las categor铆as desconocidas que puedan aparecer en el conjunto de prueba pero no en el de entrenamiento, en lugar de generar un error.\n","    * `sparse_output=False` hace que la salida sea un array NumPy denso en lugar de una matriz dispersa, lo cual es m谩s f谩cil de trabajar en este caso.\n","* **`X_encoded = encoder.fit_transform(X[categorical_cols])`**: Primero, `fit` aprende las categor铆as 煤nicas presentes en cada columna categ贸rica de `X`. Luego, `transform` aplica la codificaci贸n one-hot, creando nuevas columnas binarias (0 o 1) para cada categor铆a 煤nica. El resultado es un array NumPy llamado `X_encoded`.\n","* **`feature_names = encoder.get_feature_names_out(categorical_cols)`**: Obtiene los nombres de las nuevas columnas creadas por el one-hot encoding. Estos nombres se basan en los nombres de las columnas originales y las categor铆as 煤nicas dentro de ellas (por ejemplo, `sex_male`, `embarked_S`).\n","* **`X_encoded_df = pd.DataFrame(X_encoded, index=X.index, columns=feature_names)`**: Convertimos el array NumPy `X_encoded` en un DataFrame de Pandas llamado `X_encoded_df`, utilizando el mismo 铆ndice que el DataFrame original `X` y los nombres de las caracter铆sticas obtenidos del encoder.\n","* **`X_processed = pd.concat([X[numerical_cols], X_encoded_df], axis=1)`**: Concatenamos (unimos) las columnas num茅ricas originales de `X` con las nuevas columnas codificadas en `X_encoded_df` a lo largo de las columnas (`axis=1`). El resultado es nuestro DataFrame preprocesado `X_processed`, que ahora contiene solo datos num茅ricos.\n","* Las siguientes l铆neas de `print` muestran las primeras filas y la forma del DataFrame preprocesado. El n煤mero de columnas habr谩 aumentado debido a la expansi贸n de las variables categ贸ricas.\n","\n","**6. Divisi贸n de los Datos en Conjuntos de Entrenamiento y Prueba:**\n","\n","```python\n","# 5. Dividir los datos en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n","\n","print(\"\\nForma de X_train:\", X_train.shape)\n","print(\"Forma de X_test:\", X_test.shape)\n","print(\"Forma de y_train:\", y_train.shape)\n","print(\"Forma de y_test:\", y_test.shape)\n","```\n","\n","* Dividimos nuestro conjunto de datos preprocesado en dos partes: un conjunto de entrenamiento para que el modelo aprenda y un conjunto de prueba para evaluar qu茅 tan bien generaliza a datos nuevos.\n","* **`X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)`**: La funci贸n `train_test_split` toma las caracter铆sticas preprocesadas (`X_processed`) y la variable objetivo (`y`) como entrada.\n","    * `test_size=0.2` especifica que el 20% de los datos se utilizar谩 para el conjunto de prueba, mientras que el 80% restante se utilizar谩 para el conjunto de entrenamiento.\n","    * `random_state=42` es una semilla para el generador de n煤meros aleatorios. Usar una semilla asegura que la divisi贸n de los datos sea la misma cada vez que se ejecuta el c贸digo, lo que facilita la reproducibilidad de los resultados.\n","* Las l铆neas de `print` muestran la forma (n煤mero de filas y columnas) de los conjuntos de entrenamiento y prueba para las caracter铆sticas (`X_train`, `X_test`) y la variable objetivo (`y_train`, `y_test`).\n","\n","**7. Inicializaci贸n y Entrenamiento del Modelo de Regresi贸n Log铆stica:**\n","\n","```python\n","# 6. Inicializar y entrenar un modelo de Regresi贸n Log铆stica\n","model = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000)\n","model.fit(X_train, y_train)\n","```\n","\n","* Creamos una instancia del modelo de Regresi贸n Log铆stica y lo entrenamos con nuestros datos de entrenamiento preprocesados.\n","* **`model = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000)`**: Inicializamos un objeto `LogisticRegression`.\n","    * `solver='liblinear'` es un algoritmo de optimizaci贸n adecuado para conjuntos de datos peque帽os y medianos como el nuestro.\n","    * `random_state=42` asegura la reproducibilidad del entrenamiento del modelo.\n","    * `max_iter=1000` establece el n煤mero m谩ximo de iteraciones para que el solver converja.\n","* **`model.fit(X_train, y_train)`**: Entrenamos el modelo utilizando el conjunto de entrenamiento (`X_train` para las caracter铆sticas y `y_train` para la variable objetivo). Durante el entrenamiento, el modelo aprende la relaci贸n entre las caracter铆sticas y la probabilidad de supervivencia.\n","\n","**8. Realizaci贸n de Predicciones en el Conjunto de Prueba:**\n","\n","```python\n","# 7. Realizar predicciones en el conjunto de prueba\n","y_pred = model.predict(X_test)\n","```\n","\n","* Una vez que el modelo est谩 entrenado, lo utilizamos para hacer predicciones sobre el conjunto de prueba, que el modelo nunca ha visto antes.\n","* **`y_pred = model.predict(X_test)`**: El m茅todo `predict` del modelo toma las caracter铆sticas del conjunto de prueba (`X_test`) como entrada y devuelve un array (`y_pred`) que contiene las predicciones de supervivencia (0 o 1) para cada pasajero en el conjunto de prueba.\n","\n","**9. Evaluaci贸n del Rendimiento del Modelo:**\n","\n","```python\n","# 8. Evaluar el rendimiento del modelo\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"\\nExactitud del modelo en el conjunto de prueba (con imputaci贸n y codificaci贸n simplificadas):\", accuracy)\n","```\n","\n","* Finalmente, evaluamos qu茅 tan bien se desempe帽贸 nuestro modelo comparando sus predicciones con los valores reales de la variable objetivo en el conjunto de prueba.\n","* **`accuracy = accuracy_score(y_test, y_pred)`**: La funci贸n `accuracy_score` compara las etiquetas verdaderas del conjunto de prueba (`y_test`) con las predicciones de nuestro modelo (`y_pred`) y calcula la exactitud, que es la proporci贸n de predicciones correctas.\n","* La l铆nea de `print` muestra la exactitud del modelo en el conjunto de prueba, d谩ndonos una idea de su rendimiento en datos no vistos.\n","\n","---\n","\n","Esta explicaci贸n detallada deber铆a proporcionar a tus estudiantes una comprensi贸n clara de cada paso del c贸digo, desde la importaci贸n de librer铆as hasta la evaluaci贸n del modelo. 隆Espero que sea 煤til! 驴Qu茅 te gustar铆a abordar a continuaci贸n?"],"metadata":{"id":"0k-5pt50sfXn"}},{"cell_type":"markdown","source":["\n","---\n","\n","# **Explicaci贸n de los Resultados Paso 3:**\n","\n","**1. DataFrame despu茅s de la Imputaci贸n:**\n","\n","```\n","   pclass     sex   age  sibsp  parch     fare embarked  class    who  \\\n","0     3.0    male  22.0    1.0    0.0   7.2500        S  Third    man\n","1     1.0  female  38.0    1.0    0.0  71.2833        C  First  woman\n","2     3.0  female  26.0    0.0    0.0   7.9250        S  Third  woman\n","3     1.0  female  35.0    1.0    0.0  53.1000        S  First  woman\n","4     3.0    male  35.0    0.0    0.0   8.0500        S  Third    man\n","\n","  adult_male deck  embark_town alive  alone\n","0       True    C  Southampton    no  False\n","1      False    C    Cherbourg   yes  False\n","2      False    C  Southampton   yes   True\n","3      False    C  Southampton   yes  False\n","4       True    C  Southampton    no   True\n","```\n","\n","* Este es un vistazo a las primeras filas del DataFrame despu茅s de que aplicamos la **imputaci贸n de valores faltantes**.\n","* **Columnas Num茅ricas (como `age`, `fare`):** Los valores `NaN` que exist铆an previamente en estas columnas han sido reemplazados por la **media** de los valores presentes en cada una de esas columnas. Aunque no vemos un ejemplo directo en estas primeras filas (ya que no ten铆an `NaN`), si hubiera habido un `NaN` en la columna `age`, por ejemplo, se habr铆a llenado con la edad promedio de todos los pasajeros.\n","* **Columnas Categ贸ricas (como `embarked`, `deck`, `embark_town`):** Los valores faltantes en estas columnas han sido reemplazados por la **moda**, es decir, el valor m谩s frecuente que aparec铆a en cada una de estas columnas. En la columna `deck`, vemos una 'C' en todas las primeras filas, lo que podr铆a indicar que 'C' era la moda (el valor m谩s com煤n) si algunas de estas filas originalmente ten铆an un valor faltante en esa columna.\n","\n","**2. Valores nulos despu茅s de la imputaci贸n:**\n","\n","```\n","pclass         0\n","sex            0\n","age            0\n","sibsp          0\n","parch          0\n","fare           0\n","embarked       0\n","class          0\n","who            0\n","adult_male     0\n","deck           0\n","embark_town    0\n","alive          0\n","alone          0\n","dtype: int64\n","```\n","\n","* Este resultado es crucial. Muestra el **conteo de valores nulos (NaN)** para cada columna despu茅s de aplicar la imputaci贸n.\n","* Vemos que para cada una de las 14 columnas, el conteo de valores nulos es **0**. Esto significa que nuestra imputaci贸n ha sido exitosa y **todos los valores faltantes han sido reemplazados** utilizando las estrategias que definimos (media para num茅ricas, moda para categ贸ricas).\n","\n","**3. DataFrame despu茅s del One-Hot Encoding:**\n","\n","```\n","   pclass   age  sibsp  parch     fare  sex_female  sex_male  embarked_C  \\\n","0     3.0  22.0    1.0    0.0   7.2500         0.0       1.0         0.0\n","1     1.0  38.0    1.0    0.0  71.2833         1.0       0.0         1.0\n","2     3.0  26.0    0.0    0.0   7.9250         1.0       0.0         0.0\n","3     1.0  35.0    1.0    0.0  53.1000         1.0       0.0         0.0\n","4     3.0  35.0    0.0    0.0   8.0500         0.0       1.0         0.0\n","\n","   embarked_Q  embarked_S  ...  deck_E  deck_F  deck_G  embark_town_Cherbourg  \\\n","0         0.0         1.0  ...     0.0     0.0     0.0                    0.0\n","1         0.0         0.0  ...     0.0     0.0     0.0                    1.0\n","2         0.0         1.0  ...     0.0     0.0     0.0                    0.0\n","3         0.0         1.0  ...     0.0     0.0     0.0                    0.0\n","4         0.0         1.0  ...     0.0     0.0     0.0                    0.0\n","\n","   embark_town_Queenstown  embark_town_Southampton  alive_no  alive_yes  \\\n","0                     0.0                      1.0       1.0        0.0\n","1                     0.0                      0.0       0.0        1.0\n","2                     0.0                      1.0       0.0        1.0\n","3                     0.0                      1.0       0.0        1.0\n","4                     0.0                      1.0       1.0        0.0\n","\n","   alone_False  alone_True\n","0          1.0         0.0\n","1          1.0         0.0\n","2          0.0         1.0\n","3          1.0         0.0\n","4          0.0         1.0\n","\n","[5 rows x 32 columns]\n","```\n","\n","* Aqu铆 vemos el resultado de aplicar **One-Hot Encoding** a las columnas categ贸ricas.\n","* Las columnas num茅ricas originales (`pclass`, `age`, `sibsp`, `parch`, `fare`) se mantienen intactas.\n","* Las columnas categ贸ricas han sido transformadas. Por ejemplo, la columna original `sex` con valores 'male' y 'female' se ha convertido en dos nuevas columnas binarias: `sex_female` y `sex_male`. Para cada fila, una de estas columnas tendr谩 un valor de 1.0 (indicando la presencia de esa categor铆a) y la otra tendr谩 0.0.\n","* De manera similar, la columna `embarked` (con valores como 'S', 'C', 'Q') se ha expandido en las columnas `embarked_C`, `embarked_Q`, y `embarked_S`.\n","* Este proceso se ha repetido para todas las columnas categ贸ricas (`class`, `who`, `adult_male`, `deck`, `embark_town`, `alive`, `alone`), creando nuevas columnas binarias para cada categor铆a 煤nica dentro de ellas.\n","* La **forma del DataFrame preprocesado** ahora es `(891, 32)`. Originalmente ten铆amos 15 columnas (incluyendo la variable objetivo `survived`). Despu茅s de eliminar `survived` para el preprocesamiento y aplicar one-hot encoding a las columnas categ贸ricas, el n煤mero de columnas ha aumentado significativamente (de 14 a 32) debido a la expansi贸n de las variables categ贸ricas en m煤ltiples columnas binarias.\n","\n","**4. Formas de los conjuntos de entrenamiento y prueba:**\n","\n","```\n","Forma de X_train: (712, 32)\n","Forma de X_test: (179, 32)\n","Forma de y_train: (712,)\n","Forma de y_test: (179,)\n","```\n","\n","* Despu茅s de preprocesar los datos, los dividimos en un **conjunto de entrenamiento** y un **conjunto de prueba**.\n","* `X_train` contiene las caracter铆sticas preprocesadas para 712 pasajeros que se utilizar谩n para entrenar nuestro modelo. Tiene 32 columnas, correspondientes a las caracter铆sticas num茅ricas originales y las nuevas columnas creadas por el one-hot encoding.\n","* `X_test` contiene las mismas 32 caracter铆sticas preprocesadas para 179 pasajeros que se utilizar谩n para evaluar el rendimiento de nuestro modelo entrenado.\n","* `y_train` contiene la variable objetivo (`survived`) para los 712 pasajeros del conjunto de entrenamiento. Tiene una sola dimensi贸n.\n","* `y_test` contiene la variable objetivo para los 179 pasajeros del conjunto de prueba, que usaremos para comparar con las predicciones de nuestro modelo.\n","\n","**5. Exactitud del modelo en el conjunto de prueba:**\n","\n","```\n","Exactitud del modelo en el conjunto de prueba (con imputaci贸n y codificaci贸n simplificadas): 1.0\n","```\n","\n","* Este es el resultado de la **evaluaci贸n de nuestro modelo de Regresi贸n Log铆stica** en el conjunto de prueba.\n","* Una exactitud de **1.0** (o 100%) significa que **nuestro modelo predijo correctamente la supervivencia de todos los pasajeros en el conjunto de prueba**.\n","\n","**Puntos Importantes :**\n","\n","* Hemos logrado **manejar los valores faltantes** utilizando estrategias b谩sicas de imputaci贸n.\n","* Hemos convertido las **variables categ贸ricas en un formato num茅rico** que el modelo de Machine Learning puede entender a trav茅s del One-Hot Encoding.\n","* El n煤mero de caracter铆sticas (columnas) ha aumentado debido al One-Hot Encoding.\n","* Hemos dividido los datos preprocesados para entrenar y evaluar el modelo.\n","* El modelo de Regresi贸n Log铆stica, con este preprocesamiento, ha alcanzado una exactitud perfecta en el conjunto de prueba.\n","\n","**Precauci贸n sobre la Exactitud del 100%:**\n","\n","Es importante mencionar que una exactitud del 100% en un conjunto de prueba **debe ser examinada con escepticismo**, especialmente en problemas del mundo real. Podr铆a indicar:\n","\n","* **Un conjunto de prueba demasiado peque帽o:** Con pocos ejemplos, es m谩s f谩cil obtener una predicci贸n perfecta por casualidad.\n","* **Fugas de informaci贸n (data leakage):** Podr铆a haber alguna informaci贸n en las caracter铆sticas que indirectamente revela la variable objetivo.\n","* **Un problema demasiado simple para el modelo:** En algunos casos raros, el problema podr铆a ser inherentemente muy f谩cil de predecir.\n","\n","En los siguientes pasos, podr铆amos explorar estas posibilidades y aprender sobre la importancia de validar los modelos de manera robusta.\n"],"metadata":{"id":"hxfiKZo-vXNl"}},{"cell_type":"markdown","source":["\n","# **驴Por Qu茅 Usamos One-Hot Encoding en Lugar de Label Encoding para Variables Categ贸ricas?**\n","\n","La elecci贸n entre One-Hot Encoding y Label Encoding depende fundamentalmente de la **naturaleza de la variable categ贸rica** que estamos codificando, espec铆ficamente si existe o no una **relaci贸n de orden inherente** entre sus categor铆as.\n","\n","**Label Encoding (Codificaci贸n de Etiquetas):**\n","\n","* **驴Qu茅 hace?** Asigna un n煤mero entero 煤nico a cada categor铆a en la variable. Por ejemplo, si la columna 'Color' tiene las categor铆as 'Rojo', 'Verde' y 'Azul', Label Encoding podr铆a convertirlas en 0, 1 y 2 respectivamente.\n","* **驴Cu谩ndo podr铆a ser apropiado?** Label Encoding es m谩s apropiado para **variables categ贸ricas ordinales**. Una variable es ordinal si sus categor铆as tienen un orden o una jerarqu铆a significativa. Ejemplos:\n","    * 'Tama帽o': 'Peque帽o', 'Mediano', 'Grande' (existe un orden)\n","    * 'Nivel de Educaci贸n': 'Primaria', 'Secundaria', 'Universidad' (existe un orden)\n","    * 'Satisfacci贸n': 'Bajo', 'Medio', 'Alto' (existe un orden)\n","* **驴Cu谩l es el problema con variables nominales?** El principal problema de aplicar Label Encoding a **variables categ贸ricas nominales** (donde no existe un orden inherente entre las categor铆as, como 'Color', 'Ciudad', 'Sexo', 'Puerto de Embarque') es que **introduce una noci贸n de orden o jerarqu铆a que no existe en realidad**.\n","\n","    * Para nuestro ejemplo de 'Color' (Rojo: 0, Verde: 1, Azul: 2), el modelo podr铆a interpretar err贸neamente que 'Verde' es \"mayor que\" 'Rojo' y que 'Azul' es \"mayor que\" ambos. Esto puede confundir al algoritmo y llevar a un rendimiento sub贸ptimo, ya que el modelo podr铆a asignar m谩s peso o importancia a ciertas categor铆as bas谩ndose en el valor num茅rico asignado, en lugar de en su verdadera relaci贸n con la variable objetivo.\n","\n","**One-Hot Encoding (Codificaci贸n \"Uno Caliente\"):**\n","\n","* **驴Qu茅 hace?** Crea nuevas columnas binarias (con valores 0 o 1) para cada categor铆a 煤nica en la variable original. Por ejemplo, la columna 'Color' ('Rojo', 'Verde', 'Azul') se convertir铆a en tres nuevas columnas: 'Color_Rojo', 'Color_Verde' y 'Color_Azul'. Para cada fila, solo una de estas columnas tendr谩 un valor de 1 (indicando que esa era la categor铆a original), mientras que las otras tendr谩n 0.\n","* **驴Cu谩ndo es apropiado?** One-Hot Encoding es la t茅cnica preferida para **variables categ贸ricas nominales**. Al crear columnas separadas para cada categor铆a, evitamos introducir cualquier tipo de relaci贸n de orden o magnitud entre ellas. Cada categor铆a se trata como independiente de las dem谩s.\n","* **驴Por qu茅 es mejor para variables nominales?**\n","    * **Evita la falsa relaci贸n de orden:** Cada categor铆a tiene su propia columna, por lo que el modelo no asume ninguna jerarqu铆a entre ellas.\n","    * **Permite al modelo aprender relaciones espec铆ficas:** El modelo puede aprender una relaci贸n diferente entre cada categor铆a y la variable objetivo. Por ejemplo, la probabilidad de supervivencia podr铆a ser diferente para hombres y mujeres, y el One-Hot Encoding permite al modelo capturar estas diferencias individualmente a trav茅s de las columnas 'sex_male' y 'sex_female'.\n","\n","**En el Contexto del Dataset del Titanic:**\n","\n","La mayor铆a de las variables categ贸ricas en el dataset del Titanic son **nominales**. Considera ejemplos como:\n","\n","* **`sex` (male/female):** No hay un orden inherente entre ser hombre o mujer en t茅rminos de supervivencia.\n","* **`embarked` (C, Q, S):** Los diferentes puertos de embarque no tienen una relaci贸n ordinal natural.\n","* **`class` (First, Second, Third):** Aunque existe un orden socioecon贸mico, al tratarlos directamente como categor铆as nominales a trav茅s de One-Hot Encoding, permitimos que el modelo aprenda la relaci贸n espec铆fica de cada clase con la supervivencia sin imponer un gradiente lineal. (Podr铆a haber argumentos para Label Encoding aqu铆 si se quisiera enfatizar el orden, pero One-Hot es m谩s com煤n para evitar suposiciones).\n","* **Otras como `who`, `deck`, `embark_town`, `alive`, `alone` tambi茅n son principalmente nominales.**\n","\n","Al aplicar Label Encoding a estas variables nominales, estar铆amos impl铆citamente diciendo al modelo que existe una \"mayor que\" o \"menor que\" entre las categor铆as, lo cual no es cierto y podr铆a distorsionar el aprendizaje del modelo.\n","\n","**Excepci贸n Potencial:**\n","\n","Podr铆a haber algunas variables categ贸ricas en el dataset (como `class` mencionado anteriormente o quiz谩s alguna codificaci贸n de rangos de edad si se hubiera hecho como categor铆as) donde un Label Encoding *podr铆a* ser considerado si el orden es realmente significativo y se quiere que el modelo lo interprete como tal. Sin embargo, incluso en esos casos, One-Hot Encoding suele ser m谩s seguro para evitar interpretaciones err贸neas por parte del modelo.\n","\n","**En resumen, usamos One-Hot Encoding para las variables categ贸ricas nominales en el dataset del Titanic (y en muchos otros problemas de clasificaci贸n) porque:**\n","\n","* **Preserva la independencia de las categor铆as.**\n","* **Evita introducir relaciones de orden o magnitud artificiales.**\n","* **Permite que el modelo aprenda la influencia espec铆fica de cada categor铆a en la variable objetivo.**\n","\n","Adem谩s de los conceptos, siempre se debe enfatizar la importancia de **entender la naturaleza de los datos** antes de aplicar cualquier t茅cnica de codificaci贸n."],"metadata":{"id":"3kkODJH402__"}}]}